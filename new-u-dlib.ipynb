{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "Processing validation data...\n",
      "Training classifier...\n",
      "Evaluating model with cross-validation...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=5 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m kf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m    115\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Dev/python/recog/new-data-dlib/lib/python3.12/site-packages/sklearn/model_selection/_split.py:416\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         (\n\u001b[1;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    414\u001b[0m     )\n\u001b[0;32m--> 416\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "File \u001b[0;32m~/Dev/python/recog/new-data-dlib/lib/python3.12/site-packages/sklearn/model_selection/_split.py:147\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    145\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    146\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m--> 147\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_test_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_not\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Dev/python/recog/new-data-dlib/lib/python3.12/site-packages/sklearn/model_selection/_split.py:809\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 809\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[0;32m~/Dev/python/recog/new-data-dlib/lib/python3.12/site-packages/sklearn/model_selection/_split.py:771\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    769\u001b[0m min_groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(y_counts)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m y_counts):\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    772\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m cannot be greater than the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of members in each class.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits)\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m min_groups:\n\u001b[1;32m    776\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    777\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    778\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m members, which is less than n_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    779\u001b[0m         \u001b[38;5;241m%\u001b[39m (min_groups, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits),\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    781\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, Rotate, Resize, ShiftScaleRotate\n",
    "\n",
    "# Paths\n",
    "train_path = \"the-data/data/train_converted/\"\n",
    "val_path = \"the-data/data/val_converted/\"\n",
    "\n",
    "# Dlib models\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "face_rec_model = dlib.face_recognition_model_v1(\"dat/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "# Augmentation pipeline\n",
    "augmentations = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    Rotate(limit=15, p=0.5),\n",
    "    Resize(150, 150, p=1.0),\n",
    "    ShiftScaleRotate(p=0.3),\n",
    "])\n",
    "\n",
    "# Function to apply augmentations\n",
    "def augment_image(image):\n",
    "    augmented = augmentations(image=image)\n",
    "    return augmented['image']\n",
    "\n",
    "# Function to extract features from face\n",
    "def extract_features(image, face_rect):\n",
    "    # Load the shape predictor\n",
    "    shape_predictor = dlib.shape_predictor(\"dat/shape_predictor_68_face_landmarks.dat\")\n",
    "    \n",
    "    # Detect facial landmarks\n",
    "    shape = shape_predictor(image, face_rect)\n",
    "    \n",
    "    # Convert grayscale image to RGB\n",
    "    if len(image.shape) == 2:  # Grayscale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Compute the face descriptor\n",
    "    face_descriptor = face_rec_model.compute_face_descriptor(image, shape)\n",
    "    return np.array(face_descriptor)\n",
    "\n",
    "# Process dataset and extract features\n",
    "def process_dataset(dataset_path, augment=False):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        label = os.path.basename(root)  # Subdirectory name as label\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            image = cv2.imread(file_path)\n",
    "            if image is None:\n",
    "                print(f\"Skipping invalid file: {file_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect faces\n",
    "            faces = face_detector(gray)\n",
    "\n",
    "            for face in faces:\n",
    "                # Extract features\n",
    "                feature = extract_features(gray, face)\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "\n",
    "            # Apply augmentations if enabled\n",
    "            if augment:\n",
    "                augmented_image = augment_image(image)\n",
    "                augmented_gray = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2GRAY)\n",
    "                augmented_faces = face_detector(augmented_gray)\n",
    "                \n",
    "                for aug_face in augmented_faces:\n",
    "                    aug_feature = extract_features(augmented_gray, aug_face)\n",
    "                    features.append(aug_feature)\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load and preprocess dataset\n",
    "print(\"Processing training data...\")\n",
    "X_train, y_train = process_dataset(train_path, augment=True)\n",
    "\n",
    "print(\"Processing validation data...\")\n",
    "X_val, y_val = process_dataset(val_path, augment=False)\n",
    "\n",
    "# Encode labels to integers by fitting on both training and validation labels\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = np.concatenate((y_train, y_val))  # Combine both training and validation labels\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "\n",
    "# Apply undersampling on the training data to balance the classes\n",
    "undersample = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the model with undersampled data\n",
    "print(\"Training classifier...\")\n",
    "clf = SVC(kernel=\"linear\", class_weight='balanced', C=10, gamma='scale')\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "print(\"Evaluating model with cross-validation...\")\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_resampled, y_train_resampled):\n",
    "    X_train_fold, X_val_fold = X_train_resampled[train_index], X_train_resampled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_resampled[train_index], y_train_resampled[val_index]\n",
    "    \n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = clf.predict(X_val_fold)\n",
    "    accuracies.append(accuracy_score(y_val_fold, y_pred))\n",
    "\n",
    "# Print cross-validation accuracy\n",
    "cross_val_accuracy = np.mean(accuracies) * 100\n",
    "print(f\"Cross-Validation Accuracy: {cross_val_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Evaluating model on validation data...\")\n",
    "y_pred = clf.predict(X_val)\n",
    "validation_accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {validation_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penambahan data augmentasi, fitur ekstraksi, hyperparameter tuning, k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training and validation data...\n",
      "Training classifier with cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rebecca/Dev/python/recog/new-data-dlib/lib/python3.12/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Cross-Validation Accuracy: 93.70%\n",
      "Evaluating model on validation data...\n",
      "Validation Accuracy: 92.59%\n"
     ]
    }
   ],
   "source": [
    "# # hasil validasi : 92.59%, cross-validasi : 93.70%\n",
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import dlib\n",
    "# import numpy as np\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, Rotate, Resize, ShiftScaleRotate\n",
    "\n",
    "# # Paths\n",
    "# train_path = \"the-data/data/train_converted/\"\n",
    "# val_path = \"the-data/data/val_converted/\"\n",
    "\n",
    "# # Dlib models\n",
    "# face_detector = dlib.get_frontal_face_detector()\n",
    "# face_rec_model = dlib.face_recognition_model_v1(\"dat/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "# shape_predictor = dlib.shape_predictor(\"dat/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# # Augmentation pipeline\n",
    "# augmentations = Compose([\n",
    "#     HorizontalFlip(p=0.5),\n",
    "#     RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "#     Rotate(limit=15, p=0.5),\n",
    "#     Resize(150, 150, p=1.0),\n",
    "#     ShiftScaleRotate(p=0.3),\n",
    "# ])\n",
    "\n",
    "# # Function to apply augmentations\n",
    "# def augment_image(image):\n",
    "#     augmented = augmentations(image=image)\n",
    "#     return augmented['image']\n",
    "\n",
    "# # Function to extract features from face\n",
    "# def extract_features(image, face_rect):\n",
    "#     # Detect facial landmarks\n",
    "#     shape = shape_predictor(image, face_rect)\n",
    "#     # Convert grayscale image to RGB if needed\n",
    "#     if len(image.shape) == 2:  # Grayscale\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "#     # Compute the face descriptor\n",
    "#     face_descriptor = face_rec_model.compute_face_descriptor(image, shape)\n",
    "#     return np.array(face_descriptor)\n",
    "\n",
    "# # Process dataset and extract features\n",
    "# def process_dataset(dataset_path, augment=False):\n",
    "#     features = []\n",
    "#     labels = []\n",
    "\n",
    "#     for root, dirs, files in os.walk(dataset_path):\n",
    "#         label = os.path.basename(root)  # Subdirectory name as label\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             image = cv2.imread(file_path)\n",
    "#             if image is None:\n",
    "#                 print(f\"Skipping invalid file: {file_path}\")\n",
    "#                 continue\n",
    "\n",
    "#             # Convert to grayscale\n",
    "#             gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#             # Detect faces\n",
    "#             faces = face_detector(gray)\n",
    "#             for face in faces:\n",
    "#                 # Extract features\n",
    "#                 feature = extract_features(gray, face)\n",
    "#                 features.append(feature)\n",
    "#                 labels.append(label)\n",
    "\n",
    "#                 # Apply augmentations if enabled\n",
    "#                 if augment:\n",
    "#                     augmented_image = augment_image(image)\n",
    "#                     augmented_gray = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2GRAY)\n",
    "#                     augmented_faces = face_detector(augmented_gray)\n",
    "#                     for aug_face in augmented_faces:\n",
    "#                         aug_feature = extract_features(augmented_gray, aug_face)\n",
    "#                         features.append(aug_feature)\n",
    "#                         labels.append(label)\n",
    "\n",
    "#     return np.array(features), np.array(labels)\n",
    "\n",
    "# # Process dataset\n",
    "# print(\"Processing training and validation data...\")\n",
    "# X_train, y_train = process_dataset(train_path, augment=True)\n",
    "# X_val, y_val = process_dataset(val_path, augment=False)\n",
    "\n",
    "# # Combine labels for encoding\n",
    "# all_labels = np.concatenate((y_train, y_val))\n",
    "\n",
    "# # Encode labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(all_labels)\n",
    "# y_train = label_encoder.transform(y_train)\n",
    "# y_val = label_encoder.transform(y_val)\n",
    "\n",
    "# # Hyperparameter tuning using GridSearchCV\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'kernel': ['linear', 'rbf'],\n",
    "#     'gamma': ['scale', 0.1, 0.01]\n",
    "# }\n",
    "# clf = GridSearchCV(SVC(probability=True), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# print(\"Training classifier with cross-validation...\")\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Best parameters and cross-validation scores\n",
    "# print(f\"Best Parameters: {clf.best_params_}\")\n",
    "# print(f\"Cross-Validation Accuracy: {clf.best_score_ * 100:.2f}%\")\n",
    "\n",
    "# # Evaluate on validation set\n",
    "# print(\"Evaluating model on validation data...\")\n",
    "# y_pred = clf.predict(X_val)\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "menambahkan blur backgrond dan membuat kotak di wajah(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "Processing validation data...\n",
      "Training classifier...\n",
      "Evaluating model...\n",
      "Validation Accuracy: 30.86%\n"
     ]
    }
   ],
   "source": [
    "# hasil : 30.86%\n",
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import dlib\n",
    "# import numpy as np\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, Rotate, Resize, ShiftScaleRotate, GaussNoise\n",
    "\n",
    "# # Paths\n",
    "# train_path = \"the-data/data/train_converted/\"\n",
    "# val_path = \"the-data/data/val_converted/\"\n",
    "\n",
    "# # Dlib models\n",
    "# face_detector = dlib.get_frontal_face_detector()\n",
    "# face_rec_model = dlib.face_recognition_model_v1(\"dat/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "# shape_predictor = dlib.shape_predictor(\"dat/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# # Augmentation pipeline\n",
    "# augmentations = Compose([\n",
    "#     HorizontalFlip(p=0.5),\n",
    "#     RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "#     Rotate(limit=15, p=0.5),\n",
    "#     Resize(150, 150, p=1.0),\n",
    "#     ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.3),\n",
    "#     GaussNoise(var_limit=(10, 50), p=0.3)\n",
    "# ])\n",
    "\n",
    "# # Function to apply augmentations\n",
    "# def augment_image(image):\n",
    "#     augmented = augmentations(image=image)\n",
    "#     return augmented['image']\n",
    "\n",
    "# # Function to blur background\n",
    "# def blur_background(image, face_rects):\n",
    "#     mask = np.zeros_like(image)  # Create a black mask\n",
    "#     for rect in face_rects:\n",
    "#         x, y, w, h = rect.left(), rect.top(), rect.width(), rect.height()\n",
    "#         cv2.rectangle(mask, (x, y), (x + w, y + h), (255, 255, 255), -1)  # Mask the face region\n",
    "\n",
    "#     blurred = cv2.GaussianBlur(image, (99, 99), 30)  # Apply Gaussian blur\n",
    "#     blurred_background = np.where(mask == 255, image, blurred)  # Combine blurred background with original face region\n",
    "#     return blurred_background\n",
    "\n",
    "# # Function to extract features from face\n",
    "# def extract_features(image, face_rect):\n",
    "#     # Detect facial landmarks\n",
    "#     shape = shape_predictor(image, face_rect)\n",
    "#     # Convert grayscale image to RGB\n",
    "#     if len(image.shape) == 2:  # Grayscale\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "#     # Compute the face descriptor\n",
    "#     face_descriptor = face_rec_model.compute_face_descriptor(image, shape)\n",
    "#     return np.array(face_descriptor)\n",
    "\n",
    "# # Process dataset and extract features\n",
    "# def process_dataset(dataset_path, augment=False):\n",
    "#     features = []\n",
    "#     labels = []\n",
    "\n",
    "#     for root, dirs, files in os.walk(dataset_path):\n",
    "#         label = os.path.basename(root)  # Subdirectory name as label\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             image = cv2.imread(file_path)\n",
    "#             if image is None:\n",
    "#                 print(f\"Skipping invalid file: {file_path}\")\n",
    "#                 continue\n",
    "\n",
    "#             # Convert to grayscale\n",
    "#             gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#             # Detect faces\n",
    "#             faces = face_detector(gray)\n",
    "#             if faces:\n",
    "#                 # Blur background\n",
    "#                 blurred_image = blur_background(image, faces)\n",
    "                \n",
    "#                 for face in faces:\n",
    "#                     # Extract features\n",
    "#                     feature = extract_features(gray, face)\n",
    "#                     features.append(feature)\n",
    "#                     labels.append(label)\n",
    "\n",
    "#                     # Apply augmentations if enabled\n",
    "#                     if augment:\n",
    "#                         augmented_image = augment_image(image=blurred_image)\n",
    "#                         augmented_gray = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2GRAY)\n",
    "#                         augmented_faces = face_detector(augmented_gray)\n",
    "#                         for aug_face in augmented_faces:\n",
    "#                             aug_feature = extract_features(augmented_gray, aug_face)\n",
    "#                             features.append(aug_feature)\n",
    "#                             labels.append(label)\n",
    "\n",
    "#     return np.array(features), np.array(labels)\n",
    "\n",
    "# # Train the model\n",
    "# print(\"Processing training data...\")\n",
    "# X_train, y_train = process_dataset(train_path, augment=True)\n",
    "\n",
    "# print(\"Processing validation data...\")\n",
    "# X_val, y_val = process_dataset(val_path, augment=False)\n",
    "\n",
    "# print(\"Training classifier...\")\n",
    "# clf = SVC(kernel=\"linear\", probability=True)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Evaluating model...\")\n",
    "# y_pred = clf.predict(X_val)\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penambahan augmentasi shiftScaleRotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hasil adalah 33.95%\n",
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import dlib\n",
    "# import numpy as np\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, Rotate, Resize, ShiftScaleRotate\n",
    "# from albumentations import GaussNoise\n",
    "\n",
    "# # Paths\n",
    "# train_path = \"the-data/data/train_converted/\"\n",
    "# val_path = \"the-data/data/val_converted/\"\n",
    "\n",
    "# # Dlib models\n",
    "# face_detector = dlib.get_frontal_face_detector()\n",
    "# face_rec_model = dlib.face_recognition_model_v1(\"dat/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "\n",
    "# # Augmentation pipeline\n",
    "# augmentations = Compose([\n",
    "#     HorizontalFlip(p=0.5),\n",
    "#     RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "#     Rotate(limit=15, p=0.5),\n",
    "#     Resize(150, 150, p=1.0),\n",
    "#     ShiftScaleRotate(p=0.3),  \n",
    "# ])\n",
    "\n",
    "\n",
    "# # Function to apply augmentations\n",
    "# def augment_image(image):\n",
    "#     augmented = augmentations(image=image)\n",
    "#     return augmented['image']\n",
    "\n",
    "# # Function to extract features from face\n",
    "# def extract_features(image, face_rect):\n",
    "#     # Load the shape predictor\n",
    "#     shape_predictor = dlib.shape_predictor(\"dat/shape_predictor_68_face_landmarks.dat\")\n",
    "#     # Detect facial landmarks\n",
    "#     shape = shape_predictor(image, face_rect)\n",
    "#     # Convert grayscale image to RGB\n",
    "#     if len(image.shape) == 2:  # Grayscale\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "#     # Compute the face descriptor\n",
    "#     face_descriptor = face_rec_model.compute_face_descriptor(image, shape)\n",
    "#     return np.array(face_descriptor)\n",
    "\n",
    "\n",
    "# # Process dataset and extract features\n",
    "# def process_dataset(dataset_path, augment=False):\n",
    "#     features = []\n",
    "#     labels = []\n",
    "\n",
    "#     for root, dirs, files in os.walk(dataset_path):\n",
    "#         label = os.path.basename(root)  # Subdirectory name as label\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             image = cv2.imread(file_path)\n",
    "#             if image is None:\n",
    "#                 print(f\"Skipping invalid file: {file_path}\")\n",
    "#                 continue\n",
    "\n",
    "#             # Convert to grayscale\n",
    "#             gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#             # Detect faces\n",
    "#             faces = face_detector(gray)\n",
    "#             for face in faces:\n",
    "#                 # Extract features\n",
    "#                 feature = extract_features(gray, face)\n",
    "#                 features.append(feature)\n",
    "#                 labels.append(label)\n",
    "\n",
    "#                 # Apply augmentations if enabled\n",
    "#                 if augment:\n",
    "#                     augmented_image = augment_image(image)\n",
    "#                     augmented_gray = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2GRAY)\n",
    "#                     augmented_faces = face_detector(augmented_gray)\n",
    "#                     for aug_face in augmented_faces:\n",
    "#                         aug_feature = extract_features(augmented_gray, aug_face)\n",
    "#                         features.append(aug_feature)\n",
    "#                         labels.append(label)\n",
    "\n",
    "#     return np.array(features), np.array(labels)\n",
    "\n",
    "# # Train the model\n",
    "# print(\"Processing training data...\")\n",
    "# X_train, y_train = process_dataset(train_path, augment=True)\n",
    "\n",
    "# print(\"Processing validation data...\")\n",
    "# X_val, y_val = process_dataset(val_path, augment=False)\n",
    "\n",
    "# print(\"Training classifier...\")\n",
    "# clf = SVC(kernel=\"linear\", probability=True)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Evaluating model...\")\n",
    "# y_pred = clf.predict(X_val)\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil adalah 33.33%\n",
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import dlib\n",
    "# import numpy as np\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, Rotate, Resize\n",
    "# from albumentations import GaussNoise\n",
    "\n",
    "# # Paths\n",
    "# train_path = \"the-data/data/train_converted/\"\n",
    "# val_path = \"the-data/data/val_converted/\"\n",
    "\n",
    "# # Dlib models\n",
    "# face_detector = dlib.get_frontal_face_detector()\n",
    "# face_rec_model = dlib.face_recognition_model_v1(\"dat/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "\n",
    "# # Augmentation pipeline\n",
    "# augmentations = Compose([\n",
    "#     HorizontalFlip(p=0.5),\n",
    "#     RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "#     Rotate(limit=15, p=0.5),\n",
    "#     Resize(150, 150, p=1.0)\n",
    "# ])\n",
    "\n",
    "\n",
    "# # Function to apply augmentations\n",
    "# def augment_image(image):\n",
    "#     augmented = augmentations(image=image)\n",
    "#     return augmented['image']\n",
    "\n",
    "# # Function to extract features from face\n",
    "# def extract_features(image, face_rect):\n",
    "#     # Load the shape predictor\n",
    "#     shape_predictor = dlib.shape_predictor(\"dat/shape_predictor_68_face_landmarks.dat\")\n",
    "#     # Detect facial landmarks\n",
    "#     shape = shape_predictor(image, face_rect)\n",
    "#     # Convert grayscale image to RGB\n",
    "#     if len(image.shape) == 2:  # Grayscale\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "#     # Compute the face descriptor\n",
    "#     face_descriptor = face_rec_model.compute_face_descriptor(image, shape)\n",
    "#     return np.array(face_descriptor)\n",
    "\n",
    "\n",
    "# # Process dataset and extract features\n",
    "# def process_dataset(dataset_path, augment=False):\n",
    "#     features = []\n",
    "#     labels = []\n",
    "\n",
    "#     for root, dirs, files in os.walk(dataset_path):\n",
    "#         label = os.path.basename(root)  # Subdirectory name as label\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             image = cv2.imread(file_path)\n",
    "#             if image is None:\n",
    "#                 print(f\"Skipping invalid file: {file_path}\")\n",
    "#                 continue\n",
    "\n",
    "#             # Convert to grayscale\n",
    "#             gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#             # Detect faces\n",
    "#             faces = face_detector(gray)\n",
    "#             for face in faces:\n",
    "#                 # Extract features\n",
    "#                 feature = extract_features(gray, face)\n",
    "#                 features.append(feature)\n",
    "#                 labels.append(label)\n",
    "\n",
    "#                 # Apply augmentations if enabled\n",
    "#                 if augment:\n",
    "#                     augmented_image = augment_image(image)\n",
    "#                     augmented_gray = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2GRAY)\n",
    "#                     augmented_faces = face_detector(augmented_gray)\n",
    "#                     for aug_face in augmented_faces:\n",
    "#                         aug_feature = extract_features(augmented_gray, aug_face)\n",
    "#                         features.append(aug_feature)\n",
    "#                         labels.append(label)\n",
    "\n",
    "#     return np.array(features), np.array(labels)\n",
    "\n",
    "# # Train the model\n",
    "# print(\"Processing training data...\")\n",
    "# X_train, y_train = process_dataset(train_path, augment=True)\n",
    "\n",
    "# print(\"Processing validation data...\")\n",
    "# X_val, y_val = process_dataset(val_path, augment=False)\n",
    "\n",
    "# print(\"Training classifier...\")\n",
    "# clf = SVC(kernel=\"linear\", probability=True)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Evaluating model...\")\n",
    "# y_pred = clf.predict(X_val)\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
